{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Repsonses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioMistral-response.csv\n",
      "claude-3-sonnet-20240229-response.csv\n",
      "falcon-40b-instruct-response.csv\n",
      "gemini-1.0-pro-latest-response.csv\n",
      "gpt-4-turbo-response.csv\n",
      "HF_LLMs_Results_before_cleaning\n",
      "Include_NaN\n",
      "KTO_Mistral_PairRM-response.csv\n",
      "Llama-3-70B-Instruct-response.csv\n",
      "Llama-3-8B-Instruct-response user-only-prompt.csv\n",
      "meerkat-response.csv\n",
      "Mistral-7B-Instruct-response.csv\n",
      "Mixtral-8x22B-Instruct-response.csv\n",
      "Mixtral-8x7B-Instruct-response.csv\n",
      "MultiVerse_70B-response.csv\n",
      "Orca-2-response-do_sample=false.csv\n",
      "Phi-3-mini-4k-instruct-response.csv\n",
      "Qwen1_5-72B-response.csv\n",
      "Repeated_with_different_parameters\n",
      "Rhea-response.csv\n",
      "vicuna-33b-response.csv\n",
      "Yi-34B-response.csv\n"
     ]
    }
   ],
   "source": [
    "models_dir = \"../../../Results/LLMs_Responses\"\n",
    "\n",
    "files_list = os.listdir(models_dir)\n",
    "\n",
    "for num, file in enumerate(files_list, start=0):\n",
    "    print(num, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Yi-34B\"\n",
    "file_name = [file for file in files_list if model_name in file][0]\n",
    "\n",
    "responses_file_path = os.path.join(models_dir, file_name)\n",
    "\n",
    "responses_df = pd.read_csv(responses_file_path, encoding='utf-8')\n",
    "responses_df['Problem'] = responses_df['Problem'].apply(eval)\n",
    "\n",
    "print(file_name,\"\\n\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "responses_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to compare with a similar model, or same model with different configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_file_index = 17\n",
    "second_file_name = files_list[second_file_index]\n",
    "\n",
    "responses_file_path_2 = os.path.join(models_dir, second_file_name)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "responses_df_2 = pd.read_csv(responses_file_path_2, encoding='utf-8')\n",
    "\n",
    "diff_df = abs(responses_df_2.loc[:, 'Q1':'Q15'] - responses_df.loc[:, 'Q1':'Q15'])\n",
    "huge_difference = diff_df.gt(1).sum()  # Adjusted indexing here\n",
    "diff_df.head()\n",
    "huge_difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_none = (responses_df.isna() | responses_df.isnull()).sum()\n",
    "columns_with_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "rows_with_none = responses_df[responses_df.iloc[:,:-1].isnull().any(axis=1)]\n",
    "print(\"Rows with NaN values:\", rows_with_none.index.tolist())\n",
    "rows_with_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display individual response\n",
    "index_to_display = 9\n",
    "response_number = 8\n",
    "\n",
    "text = responses_df.at[index_to_display, f\"Response_{response_number}\"]\n",
    "\n",
    "display(HTML(\"<div style='white-space: pre-wrap;'>{}</div>\".format(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_with_problems = responses_df[responses_df['Problem'].apply(lambda x: len(x) > 0)].index.tolist()\n",
    "print(indices_with_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if indices_with_problems:\n",
    "    index_with_problem = 36\n",
    "    responses_with_problem_list = list(responses_df.loc[index_with_problem, 'Problem'])\n",
    "    print(responses_with_problem_list)\n",
    "\n",
    "    response_with_problem = responses_with_problem_list[0]\n",
    "    text = responses_df.loc[index_with_problem, f\"Response_{response_with_problem}\"]\n",
    "    display(HTML(\"<div style='white-space: pre-wrap;'>{}</div>\".format(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display responses for a selected video\n",
    "index_to_display = 207\n",
    "for question_num in range(1, 16):\n",
    "    text = responses_df.loc[index_to_display,f\"Response_{question_num}\"]\n",
    "\n",
    "    print(f\"Q{question_num}:\", end=\" \")\n",
    "    display(HTML(\"<div style='white-space: pre-wrap;'>{}</div>\".format(text)))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
